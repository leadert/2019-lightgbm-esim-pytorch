{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein\n",
    "import pyemd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial.distance import minkowski, correlation, cityblock, braycurtis, cosine, euclidean\n",
    "\n",
    "train_path = \"/home/kesci/temporary/train_tail_50M.csv\"\n",
    "train_feature_path = \"/home/kesci/work/train_tail_50M_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESS_NUM = 7\n",
    "\n",
    "# ******************** 特征处理接口 ********************\n",
    "def cal_length(string_query, string_title):\n",
    "    query_length = len(string_query.replace(\"\\t\", \"\").split(\" \"))\n",
    "    title_length = len(string_title.replace(\"\\t\", \"\").split(\" \"))\n",
    "    length_dif = abs(query_length - title_length)\n",
    "    len_ratio = query_length / title_length\n",
    "    return query_length, title_length, length_dif, len_ratio\n",
    "\n",
    "def longest_common_subsequence(string_query, string_title):  # 最长公共子序列\n",
    "    list_query = string_query.replace(\"\\t\", \"\").split(\" \")\n",
    "    list_title = string_title.replace(\"\\t\", \"\").split(\" \")\n",
    "\n",
    "    length_query = len(list_query)\n",
    "    length_title = len(list_title)\n",
    "    value = np.zeros((length_query + 1, length_title + 1))\n",
    "    for i in range(1, length_query + 1):\n",
    "        for j in range(1, length_title + 1):\n",
    "            if list_query[i - 1] == list_title[j - 1]:\n",
    "                value[i][j] = value[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                value[i][j] = max(value[i - 1][j], value[i][j - 1])\n",
    "    max_value = value.max()\n",
    "    query_start, query_end, title_start, title_end = cal_start_and_end(value, int(max_value))\n",
    "    return max_value, (query_end - query_start) / length_query, (title_end - title_start) / length_title, max_value/length_title\n",
    "\n",
    "def cal_start_and_end(value, len):\n",
    "    query_start = 0\n",
    "    query_end = 0\n",
    "    title_start = 0\n",
    "    title_end = 0\n",
    "    init = 0\n",
    "    count = 0\n",
    "    m, n = value.shape\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            if int(value[i][j]) > init:\n",
    "                if count == 0:\n",
    "                    query_start = i\n",
    "                    title_start = j\n",
    "                count += 1\n",
    "                init = int(value[i][j])\n",
    "                if count == len:\n",
    "                    query_end = i\n",
    "                    title_end = j\n",
    "                    break\n",
    "    return query_start, query_end, title_start, title_end\n",
    "\n",
    "def longest_common_substring(string_query, string_title):  # 最长公共子串, 子串起始位置比，子串平均位置比, 所有可能子串能够达到的密度\n",
    "    list_query = string_query.replace(\"\\t\", \"\").split(\" \")\n",
    "    list_title = string_title.replace(\"\\t\", \"\").split(\" \")\n",
    "\n",
    "    length_query = len(list_query)\n",
    "    length_title = len(list_title)\n",
    "    value = np.zeros((length_query + 1, length_title + 1))\n",
    "    index = np.zeros((length_query + 1, length_title + 1))\n",
    "    for i in range(1, length_query + 1):\n",
    "        for j in range(1, length_title + 1):\n",
    "            if list_query[i - 1] == list_title[j - 1]:\n",
    "                value[i][j] = value[i - 1][j - 1] + 1\n",
    "                index[i][j] = index[i - 1][j - 1] + j\n",
    "            else:\n",
    "                value[i][j] = 0\n",
    "                index[i][j] = 0\n",
    "    max_value = value.max()\n",
    "\n",
    "    if max_value != 0:\n",
    "        row = int(np.where(value == np.max(value))[0][0])\n",
    "        column = int(np.where(value == np.max(value))[1][0])\n",
    "        start_location = (column - max_value + 1) / length_title\n",
    "        mean_location = index[row][column] / (max_value * length_title)  # 防止max_value=0造成np.NAN\n",
    "        rows = np.where(value != 0.0)[0]\n",
    "        columns = np.where(value != 0.0)[1]\n",
    "        total_loc = 0\n",
    "        for i in range(0, len(rows)):\n",
    "            total_loc += index[rows[i]][columns[i]]\n",
    "        den_ratio = total_loc / (length_query * length_title)\n",
    "        lcs_ratio_qlen = max_value / length_query\n",
    "        lcs_ratio_tlen = max_value / length_title\n",
    "    else:\n",
    "        start_location,mean_location,total_loc,den_ratio,lcs_ratio_qlen,lcs_ratio_tlen = 0,0,0,0,0,0\n",
    "    return max_value, start_location, mean_location, total_loc, den_ratio, lcs_ratio_qlen,lcs_ratio_tlen\n",
    "\n",
    "def common_words(string_query, string_title): \n",
    "    list_query = string_query.replace(\"\\t\", \"\").split(\" \")\n",
    "    list_title = string_title.replace(\"\\t\", \"\").split(\" \")\n",
    "    set_query = set(list_query)\n",
    "    set_title = set(list_title)\n",
    "    total_unique_words = len(set_query.union(set_title))\n",
    "\n",
    "    common_words = [word for word in list_title if word in list_query]\n",
    "    common_words_set = set(common_words)\n",
    "    unique_ratio = len(common_words_set)/total_unique_words\n",
    "\n",
    "    shared_words_in_q1 = [w for w in list_query if w in list_title]\n",
    "    shared_words_in_q2 = [w for w in list_title if w in list_query]\n",
    "    qt_length_ratio = (len(shared_words_in_q1) + len(shared_words_in_q2)) / (len(list_query) + len(list_title))\n",
    "    if len(common_words) > 0:\n",
    "        com_index1 = len(common_words)\n",
    "        com_in_q = com_index1/len(list_query)\n",
    "        com_in_t = com_index1/len(list_title)\n",
    "\n",
    "        for word in common_words_set:\n",
    "            index_list = [i for i, x in enumerate(list_query) if x == word]\n",
    "            com_index1 += sum(index_list)\n",
    "        query_location = com_index1 / (len(list_query) * len(common_words))\n",
    "        com_index2 = len(common_words)\n",
    "        for word in common_words_set:\n",
    "            index_list = [i for i, x in enumerate(list_title) if x == word]\n",
    "            com_index2 += sum(index_list)\n",
    "        title_location = com_index2 / (len(list_title) * len(common_words))\n",
    "\n",
    "        com_set_in_q = len(common_words_set) / len(set_query)\n",
    "        com_set_in_t = len(common_words_set) / len(set_title)\n",
    "        qt_set_ratio = 2 * len(common_words_set) / (len(set_query) + len(set_title))\n",
    "\n",
    "        com_set_query_index = len(common_words_set)\n",
    "        for word in common_words_set:\n",
    "            index_list = [i for i, x in enumerate(list_query) if x == word]\n",
    "            if len(index_list) > 0:\n",
    "                com_set_query_index += index_list[0]\n",
    "        query_set_location = com_set_query_index / (len(list_query) * len(common_words_set))\n",
    "        com_set_title_index = len(common_words_set)\n",
    "        for word in common_words_set:\n",
    "            index_list = [i for i, x in enumerate(list_title) if x == word]\n",
    "            if len(index_list) > 0:\n",
    "                com_set_title_index += index_list[0]\n",
    "        title_set_location = com_set_title_index / (len(list_title) * len(common_words_set))\n",
    "        set_ratio = (len(common_words_set) / len(common_words))\n",
    "    else:\n",
    "        unique_ratio,qt_length_ratio, com_in_q, com_in_t, query_location, title_location, com_set_in_q, com_set_in_t, qt_set_ratio, query_set_location, title_set_location, set_ratio = 0,0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    return unique_ratio,qt_length_ratio, com_in_q, com_in_t, query_location, title_location, com_set_in_q, com_set_in_t, qt_set_ratio, query_set_location, title_set_location, set_ratio\n",
    "\n",
    "def cal_fuzz_ratio(string_query, string_title):  # fuzz特征\n",
    "    token_sort_value = fuzz.token_sort_ratio(string_query, string_title)\n",
    "    token_set_value = fuzz.token_set_ratio(string_query, string_title)\n",
    "    return token_sort_value, token_set_value\n",
    "\n",
    "def cal_levenshtein(string_query, string_title):  # levenshtein特征\n",
    "    leven_jaro = Levenshtein.jaro(string_query, string_title)\n",
    "    leven_distance = Levenshtein.distance(string_query, string_title)\n",
    "    leven_ratio = Levenshtein.ratio(string_query, string_title)\n",
    "    return leven_jaro, leven_distance, leven_ratio\n",
    "\n",
    "def jaccard_sim(string_query, string_title):\n",
    "    list_query = string_query.replace(\"\\t\", \"\").split(\" \")\n",
    "    list_title = string_title.replace(\"\\t\", \"\").split(\" \")\n",
    "    unions = len(set(list_query).union(set(list_title)))\n",
    "    intersections = len(set(list_query).intersection(set(list_title)))\n",
    "    return intersections / unions\n",
    "\n",
    "def cal_words_movement(string_query, string_title):\n",
    "    list_query = string_query.replace(\"\\t\", \"\").split(\" \")\n",
    "    list_title = string_title.replace(\"\\t\", \"\").split(\" \")\n",
    "    words_value = word_vectors.wmdistance(list_query, list_title)\n",
    "    return words_value\n",
    "def extract_unique_words(string_query, string_title): \n",
    "    list_query = string_query.replace(\"\\t\", \"\").split(\" \")\n",
    "    list_title = string_title.replace(\"\\t\", \"\").split(\" \")\n",
    "    \n",
    "    query_words = [word for word in list_query if word not in list_title]\n",
    "    title_words = [word for word in list_title if word not in list_query]\n",
    "    return query_words, title_words\n",
    "def cal_nlp_sim(string_query, string_title):\n",
    "    list_query = string_query.replace(\"\\t\", \"\").split(\" \")\n",
    "    list_title = string_title.replace(\"\\t\", \"\").split(\" \")\n",
    "    M_query = []\n",
    "    for word in list_query:\n",
    "        if word_vectors.__contains__(word):\n",
    "            M_query.append(word_vectors.__getitem__(word))\n",
    "    M_query = np.array(M_query)\n",
    "    if len(M_query) != 0:\n",
    "        q_sentence_vec = M_query.sum(axis=0) / M_query.shape[0]\n",
    "    else:\n",
    "        q_sentence_vec = np.zeros((150,), dtype=np.float32)\n",
    "\n",
    "    M_title = []\n",
    "    for word in list_title:\n",
    "        if word_vectors.__contains__(word):\n",
    "            M_title.append(word_vectors.__getitem__(word))\n",
    "    M_title = np.array(M_title)\n",
    "    if len(M_title) != 0:\n",
    "        t_sentence_vec = M_title.sum(axis=0) / M_title.shape[0]\n",
    "    else:\n",
    "        t_sentence_vec = np.zeros((150,), dtype=np.float32)\n",
    "    dot_product = np.sum(np.multiply(q_sentence_vec, t_sentence_vec))  # 点积\n",
    "    braycurtis_value = braycurtis(q_sentence_vec, t_sentence_vec)\n",
    "    cityblock_value = cityblock(q_sentence_vec, t_sentence_vec)\n",
    "    correlation_value = correlation(q_sentence_vec, t_sentence_vec)\n",
    "    cosine_value = cosine(q_sentence_vec, t_sentence_vec)\n",
    "    euclidean_value = euclidean(q_sentence_vec, t_sentence_vec)\n",
    "    minkowski_value = minkowski(q_sentence_vec, t_sentence_vec, p=3)\n",
    "    return dot_product, braycurtis_value, cityblock_value, correlation_value, cosine_value, euclidean_value, minkowski_value\n",
    "\n",
    "def cal_nlp_dis(string_query, string_title):\n",
    "    list_query, list_title = extract_unique_words(string_query, string_title)\n",
    "    M_query = []\n",
    "    for word in list_query:\n",
    "        if word_vectors.__contains__(word):\n",
    "            M_query.append(word_vectors.__getitem__(word))\n",
    "    M_query = np.array(M_query)\n",
    "    if len(M_query) != 0:\n",
    "        q_sentence_vec = M_query.sum(axis=0) / M_query.shape[0]\n",
    "    else:\n",
    "        q_sentence_vec = np.zeros((150,), dtype=np.float32)\n",
    "    M_title = []\n",
    "    for word in list_title:\n",
    "        if word_vectors.__contains__(word):\n",
    "            M_title.append(word_vectors.__getitem__(word))\n",
    "    M_title = np.array(M_title)\n",
    "    if len(M_title) != 0:\n",
    "        t_sentence_vec = M_title.sum(axis=0) / M_title.shape[0]\n",
    "    else:\n",
    "        t_sentence_vec = np.zeros((150,), dtype=np.float32)\n",
    "    dis_dot_product = np.sum(np.multiply(q_sentence_vec, t_sentence_vec))  # 点积\n",
    "    dis_braycurtis_value = braycurtis(q_sentence_vec, t_sentence_vec)\n",
    "    dis_cityblock_value = cityblock(q_sentence_vec, t_sentence_vec)\n",
    "    dis_correlation_value = correlation(q_sentence_vec, t_sentence_vec)\n",
    "    dis_cosine_value = cosine(q_sentence_vec, t_sentence_vec)\n",
    "    dis_euclidean_value = euclidean(q_sentence_vec, t_sentence_vec)\n",
    "    dis_minkowski_value = minkowski(q_sentence_vec, t_sentence_vec, p=3)\n",
    "    if dis_dot_product == 'nan':\n",
    "        dis_dot_product = 2\n",
    "    if dis_braycurtis_value == 'nan':\n",
    "        dis_braycurtis_value = 2\n",
    "    if dis_cityblock_value == 'nan':\n",
    "        dis_cityblock_value = 2\n",
    "    if dis_correlation_value == 'nan':\n",
    "        dis_correlation_value = 2\n",
    "    if dis_cosine_value == 'nan':\n",
    "        dis_cosine_value = 2\n",
    "    if dis_euclidean_value == 'nan':\n",
    "        dis_euclidean_value = 2\n",
    "    if dis_minkowski_value == 'nan':\n",
    "        dis_minkowski_value = 2\n",
    "    return dis_dot_product, dis_braycurtis_value, dis_cityblock_value, dis_correlation_value, dis_cosine_value, dis_euclidean_value, dis_minkowski_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************** 特征抽取模块 ********************\n",
    "def extract_features(query_title):\n",
    "    df = pd.DataFrame()\n",
    "    print(\"length features\")\n",
    "    df[\"query_id\"] = query_title[\"query_id\"]\n",
    "    df[\"query_length\"], df[\"title_length\"], df[\"query_length_sub_title_length\"], df[\"query_length_ratio_title_length\"] = zip(\n",
    "        *query_title.apply(lambda x: cal_length(x[\"query\"], x[\"title\"]), axis=1))\n",
    "\n",
    "    print(\"longest common subsequence features\")\n",
    "    df[\"longest_common_subsequence\"],df[\"longest_common_subsequence_query_ratio\"], \\\n",
    "    df[\"longest_common_subsequence_title_ratio\"], df[\"lcsubsequence_ratio_t_length\",] = zip(\n",
    "        *query_title.apply(lambda x: longest_common_subsequence(x[\"query\"], x[\"title\"]), axis=1))  # 使用多列生成多列\n",
    "\n",
    "    print(\"longest common substring features\")\n",
    "    df[\"longest_common_substring\"],df[\"lcs_start_location_ratio\"], df[\"lcs_mean_location_ratio\"], df[\"lcs_total_loc_ratio\"], \\\n",
    "    df[\"lcs_dense_ratio\"],df[\"lcstring_ratio_q_length\"],df[\"lcstring_ratio_t_length\"] = zip(\n",
    "        *query_title.apply(lambda x: longest_common_substring(x[\"query\"], x[\"title\"]), axis=1))  # 使用多列生成多列\n",
    "\n",
    "    print(\"common words features\")\n",
    "    df[\"unique_ratio\"],\\\n",
    "    df[\"share_words_qt_length_ratio\"], df[\"query_common_words_len_ratio\"], df[\"title_common_words_len_ratio\"], \\\n",
    "    df[\"query_common_words_loc_ratio\"], df[\"title_common_words_loc_ratio\"], \\\n",
    "    df[\"query_common_set_ratio\"], df[\"title_common_set_ratio\"], df[\"query_title_set_ratio\"], \\\n",
    "    df[\"query_common_set_loc_ratio\"], df[\"title_common_set_loc_ratio\"], df[\"common_set_ratio\"] = zip(\n",
    "        *query_title.apply(lambda x: common_words(x[\"query\"], x[\"title\"]), axis=1))\n",
    "\n",
    "    print(\"nlp features\")\n",
    "    df[\"fuzz_token_sort_ratio\"], df[\"fuzz_token_set_ratio\"] = zip(\n",
    "        *query_title.apply(lambda x: cal_fuzz_ratio(x[\"query\"], x[\"title\"]), axis=1))\n",
    "    df[\"levenshtein_jaro\"], df[\"levenshtein_distance\"], df[\"levenshtein_ratio\"] = zip(\n",
    "        *query_title.apply(lambda x: cal_levenshtein(x[\"query\"], x[\"title\"]), axis=1))\n",
    "    df[\"jaccard_sim\"] = query_title.apply(lambda x: jaccard_sim(x[\"query\"], x[\"title\"]), axis=1)\n",
    "    df[\"words_movement_distance\"] = query_title.apply(lambda x: cal_words_movement(x[\"query\"], x[\"title\"]), axis=1)\n",
    "    df[\"dot_product\"], df[\"braycurtis\"], df[\"cityblock\"], df[\"correlation\"], df[\"cosine\"], df[\"euclidean\"], df[\"minkowski\"] = zip(\n",
    "        *query_title.apply(lambda x: cal_nlp_sim(x[\"query\"], x[\"title\"]), axis=1))\n",
    "    df[\"dis_dot_product\"], df[\"dis_braycurtis\"], df[\"dis_cityblock\"], df[\"dis_correlation\"], df[\"dis_cosine\"], df[\"dis_euclidean\"], df[\"dis_minkowski\"] = zip(\n",
    "        *query_title.apply(lambda x: cal_nlp_dis(x[\"query\"], x[\"title\"]), axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************** 内存监控模块 ********************\n",
    "import psutil\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "def getMemorystate():\n",
    "    phymem = psutil.virtual_memory()\n",
    "    line = \"Memory: %5s%% %6s/%s\" % (\n",
    "        phymem.percent,\n",
    "        str(int(phymem.used / 1024 / 1024)) + \"M\",\n",
    "        str(int(phymem.total / 1024 / 1024)) + \"M\")\n",
    "    return line\n",
    "\n",
    "# ******************** 多线程模块 ********************\n",
    "def process_pool_test(data_path, feature_path):\n",
    "    names = ['query_id',\n",
    "\n",
    "             'query_length',\n",
    "             'title_length',\n",
    "\n",
    "             'longest_common_subsequence','longest_common_subsequence_query_ratio',\n",
    "             'longest_common_subsequence_title_ratio',\"lcsubsequence_ratio_t_length\",\n",
    "\n",
    "             'longest_common_substring','lcs_start_location_ratio','lcs_mean_location_ratio',\n",
    "             'lcs_total_loc_ratio', 'lcs_dense_ratio','lcstring_ratio_q_length','lcstring_ratio_t_length',\n",
    "\n",
    "             'unique_ratio',\n",
    "             'share_words_qt_length_ratio', 'query_common_words_len_ratio', 'title_common_words_len_ratio',\n",
    "             'query_common_words_loc_ratio', 'title_common_words_loc_ratio',\n",
    "             'query_common_set_ratio', 'title_common_set_ratio', 'query_title_set_ratio',\n",
    "             'query_common_set_loc_ratio', 'title_common_set_loc_ratio', 'common_set_ratio',\n",
    "\n",
    "             'query_nunique_title','title_nunique_query',\n",
    "\n",
    "             'fuzz_token_sort_ratio','fuzz_token_set_ratio',\n",
    "             'levenshtein_jaro','levenshtein_distance','levenshtein_ratio',\n",
    "             'jaccard_sim',\n",
    "             'words_movement_distance',\n",
    "             'dot_product','braycurtis','cityblock','correlation','cosine','euclidean','minkowski',\n",
    "             'dis_dot_product','dis_braycurtis','dis_cityblock','dis_correlation','dis_cosine','dis_euclidean','dis_minkowski']\n",
    "\n",
    "    df = pd.DataFrame(columns=names)\n",
    "    df.to_csv(feature_path, index=False, header=True)\n",
    "    query_title = pd.read_csv(data_path, usecols=[0, 1, 3], chunksize=1000000, header=None,\n",
    "                              names=[\"query_id\", \"query\", \"title\"])\n",
    "    with ProcessPoolExecutor(PROCESS_NUM) as executor:\n",
    "        t0 = time.time()\n",
    "        result = executor.map(extract_features, query_title)\n",
    "        print('finish extract')\n",
    "        print(getMemorystate())\n",
    "        for index, res in enumerate(result):\n",
    "            print(index)\n",
    "            res.to_csv(feature_path, mode='a', header=False, index=False)\n",
    "            print(getMemorystate())\n",
    "        elapsed = time.time() - t0\n",
    "        msg = '\\njob finished in {:.2f}s'\n",
    "        print(msg.format(elapsed))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ******************** 预处理部分 ********************\n",
    "    print(\"******************* peocess train tail 50m *******************\")\n",
    "    process_pool_test(train_path, train_feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单进程处理模块\n",
    "'''\n",
    "['query_length_sub_title_length',\n",
    "     'query_length_ratio_title_length',\n",
    "\n",
    "     'mean_title_length',\n",
    "     'query_length_ratio_mean_title_length',\n",
    "     'title_length_ratio_mean_title_length',\n",
    "     'query_length_sub_mean_title_length',\n",
    "     'title_length_sub_mean_title_length',\n",
    "     'query_nunique_title',\n",
    "     'title_nunique_query'\n",
    "]\n",
    "'''\n",
    "df[\"query_length_ratio_title_length\"] = df[\"query_length\"] / df[\"title_length\"]\n",
    "df[\"mean_title_length\"] = df.groupby(\"query_id\").title_length.transform(\"mean\")\n",
    "df[\"query_length_sub_mean_title_length\"] = df[\"query_length\"] - df[\"mean_title_length\"]\n",
    "df[\"title_length_sub_mean_title_length\"] = df[\"title_length\"] - df[\"mean_title_length\"]\n",
    "df[\"query_length_ratio_mean_title_length\"] = df[\"query_length\"] / df[\"mean_title_length\"]\n",
    "df[\"title_length_ratio_mean_title_length\"] = df[\"title_length\"] / df[\"mean_title_length\"]\n",
    "df[\"query_nunique_title\"] = query_title.groupby(\"query\").title.transform(\"nunique\")\n",
    "df[\"title_nunique_query\"] = query_title.groupby(\"title\").query.transform(\"nunique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有\n",
    "features_name1 = [\n",
    "    'query_id', 'title_id', 'label', 'query_length', 'title_length',\n",
    "    'query_length_sub_title_length', 'query_length_ratio_title_length',\n",
    "    'mean_title_length', 'query_length_sub_mean_title_length',\n",
    "    'title_length_sub_mean_title_length',\n",
    "    'query_length_ratio_mean_title_length',\n",
    "    'title_length_ratio_mean_title_length', 'query_nunique_title',\n",
    "    'title_nunique_query', \n",
    "    'longest_common_subsequence',\n",
    "    'longest_common_subsequence_query_ratio',\n",
    "    'longest_common_subsequence_title_ratio',\n",
    "    'lcsubsequence_ratio_t_length', 'longest_common_substring',\n",
    "    'lcs_start_location_ratio', 'lcs_mean_location_ratio',\n",
    "    'lcs_total_loc_ratio', 'lcs_dense_ratio', 'lcstring_ratio_q_length',\n",
    "    'lcstring_ratio_t_length', 'unique_ratio',\n",
    "    'share_words_qt_length_ratio', \n",
    "    \n",
    "    'query_common_words_len_ratio',\n",
    "    'title_common_words_len_ratio', \n",
    "    'query_common_words_loc_ratio',\n",
    "    'title_common_words_loc_ratio', \n",
    "    'query_common_set_ratio',\n",
    "    'title_common_set_ratio', \n",
    "    'query_title_set_ratio',\n",
    "    'query_common_set_loc_ratio', \n",
    "    'title_common_set_loc_ratio',\n",
    "    'common_set_ratio', \n",
    "    \n",
    "    'fuzz_token_sort_ratio', 'fuzz_token_set_ratio',\n",
    "    'levenshtein_jaro', 'levenshtein_distance', 'levenshtein_ratio',\n",
    "    'jaccard_sim', 'words_movement_distance', 'dot_product', 'braycurtis', 'cityblock',\n",
    "    'correlation', 'cosine', 'euclidean', 'minkowski',\n",
    "    'dis_dot_product', 'dis_braycurtis', 'dis_cityblock',\n",
    "    'dis_correlation', 'dis_cosine', 'dis_euclidean', 'dis_minkowski']\n",
    "\n",
    "\n",
    "# 最好记录\n",
    "features_name2 = [\n",
    "    'query_length', 'title_length',\n",
    "    'query_length_sub_title_length', 'query_length_ratio_title_length',\n",
    "    'mean_title_length', 'query_length_sub_mean_title_length',\n",
    "    'title_length_sub_mean_title_length',\n",
    "    'query_length_ratio_mean_title_length',\n",
    "    'title_length_ratio_mean_title_length', 'query_nunique_title',\n",
    "    'title_nunique_query', \n",
    "    'longest_common_subsequence',\n",
    "    'longest_common_subsequence_query_ratio',\n",
    "    'longest_common_subsequence_title_ratio',\n",
    "    'lcsubsequence_ratio_t_length', 'longest_common_substring',\n",
    "    'lcs_start_location_ratio', 'lcs_mean_location_ratio',\n",
    "    'lcs_total_loc_ratio', 'lcs_dense_ratio', 'lcstring_ratio_q_length',\n",
    "    'lcstring_ratio_t_length', 'unique_ratio',\n",
    "    'share_words_qt_length_ratio', \n",
    "    \n",
    "    'query_common_words_len_ratio',\n",
    "    'title_common_words_len_ratio', \n",
    "    'query_common_words_loc_ratio',\n",
    "    'title_common_words_loc_ratio', \n",
    "    'query_common_set_ratio',\n",
    "    'title_common_set_ratio', \n",
    "    'query_title_set_ratio',\n",
    "    'query_common_set_loc_ratio', \n",
    "    'title_common_set_loc_ratio',\n",
    "    'common_set_ratio', \n",
    "    \n",
    "    'fuzz_token_sort_ratio', 'fuzz_token_set_ratio',\n",
    "    'levenshtein_jaro', 'levenshtein_distance', 'levenshtein_ratio',\n",
    "    'jaccard_sim', 'words_movement_distance', 'dot_product', 'braycurtis', 'cityblock',\n",
    "    'correlation', 'cosine', 'euclidean', 'minkowski',\n",
    "    'dis_dot_product', 'dis_braycurtis', 'dis_cityblock',\n",
    "    'dis_correlation', 'dis_cosine', 'dis_euclidean', 'dis_minkowski']\n",
    "\n",
    "features2 = features[features_name2].values\n",
    "print(features2.shape)\n",
    "labels = features['label'].values\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb训练\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "X, val_x, y, val_y = train_test_split(features2, labels, test_size=0.1, random_state=1)\n",
    "del labels\n",
    "del features2\n",
    "print(\"finished\")\n",
    "\n",
    "print(\"train model\")\n",
    "t0 = time.time()\n",
    "gbm = lgb.LGBMClassifier(boosting_type=\"gbdt\", objective=\"binary\", num_leaves=127,\n",
    "                reg_alpha=5,reg_lambda=5, n_estimators=5000, feature_fraction=0.8, bagging_fraction=0.8,\n",
    "                subsample_freq=1, learning_rate=0.05, random_state=8012, n_jobs=14)\n",
    "gbm.fit(X, y, eval_metric=[\"auc\"], eval_set=(val_x, val_y), early_stopping_rounds=35)\n",
    "print(gbm.feature_importances_)\n",
    "print(time.time()-t0)\n",
    "\n",
    "joblib.dump(\"/home/kesci/temp/lgb_final_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = gbm.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果写入文件\n",
    "import csv\n",
    "\n",
    "with open(\"/home/kesci/work/score_file/result_lgb_final.csv\", \"w\", newline=\"\") as result_csvfile:\n",
    "    writer = csv.writer(result_csvfile)\n",
    "    for (query, title, score) in zip(df_test[\"query_id\"], df_test[\"title_id\"], predict_result):\n",
    "        writer.writerow([query, title, score])\n",
    "    print(\"Finished!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l /home/kesci/work/score_file/result_lgb_final.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
